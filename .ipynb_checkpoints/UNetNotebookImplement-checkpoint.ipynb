{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "089f0db9-d854-4c09-8141-86679fcfdcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from osgeo import gdal    ## used to read images in memory\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "################################################################\n",
    "## Storing and timing Models\n",
    "import pickle\n",
    "from joblib import dump,load\n",
    "import time\n",
    "\n",
    "################################################################\n",
    "# Custom functions from lib.py\n",
    "from lib import dataExtract, dataStack, indicesFromDataStack, \\\n",
    "                stochasticPCAFromDataStack, stochasticICAFromDataStack, \\\n",
    "                stackToImage, featuresCompute, \\\n",
    "                vectorStackToImage, stackToImage2, preProcessImgs2\n",
    "\n",
    "################################################################\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "################################################################\n",
    "\n",
    "plotBool = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa589b91-393f-4978-b820-9de2c644db7e",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Display Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59d734a4-1f52-4c2f-9026-481b1c8031a3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if plotBool == 1:\n",
    "    '''\n",
    "    Extract Data\n",
    "    '''\n",
    "    colNames = ['coastal','blue','green','yellow','red','red edge','near IR1', 'near IR2','AGL','CLS']\n",
    "    rawDataTrain = dataExtract(foldername='train')\n",
    "    numImages = len(rawDataTrain)\n",
    "\n",
    "    imgIdx = 1   ## index of image to plot\n",
    "\n",
    "    fig,ax = plt.subplots(nrows=3,ncols=3,figsize=(12,10))\n",
    "    img = ax[0][0].imshow(rawDataTrain['MSI'][imgIdx][0].astype(np.uint8), cmap='Blues'); ax[0][0].set_title('Coastal: 400-450 nm'); fig.colorbar(img, ax=ax[0][0], fraction=0.05)\n",
    "    img = ax[0][1].imshow(rawDataTrain['MSI'][imgIdx][1].astype(np.uint8), cmap='Blues'); ax[0][1].set_title('Blue: 450-510 nm'); fig.colorbar(img, ax=ax[0][1], fraction=0.05)\n",
    "    img = ax[0][2].imshow(rawDataTrain['MSI'][imgIdx][2].astype(np.uint8), cmap='Greens'); ax[0][2].set_title('Green: 510-580 nm'); fig.colorbar(img, ax=ax[0][2], fraction=0.05)\n",
    "    img = ax[1][0].imshow(rawDataTrain['MSI'][imgIdx][3].astype(np.uint8), cmap='YlOrRd_r'); ax[1][0].set_title('Yellow: 585-625 nm'); fig.colorbar(img, ax=ax[1][0], fraction=0.05)\n",
    "    img = ax[1][1].imshow(rawDataTrain['MSI'][imgIdx][4].astype(np.uint8), cmap='Reds'); ax[1][1].set_title('Red: 630-690 nm'); fig.colorbar(img, ax=ax[1][1], fraction=0.05)\n",
    "    img = ax[1][2].imshow(rawDataTrain['MSI'][imgIdx][5].astype(np.uint8), cmap='Reds'); ax[1][2].set_title('Red Edge: 705-745 nm'); fig.colorbar(img, ax=ax[1][2], fraction=0.05)\n",
    "    img = ax[2][0].imshow(rawDataTrain['MSI'][imgIdx][6].astype(np.uint8), cmap='Oranges'); ax[2][0].set_title('near IR1: 770-895 nm'); fig.colorbar(img, ax=ax[2][0], fraction=0.05)\n",
    "    img = ax[2][1].imshow(rawDataTrain['MSI'][imgIdx][7].astype(np.uint8), cmap='Oranges'); ax[2][1].set_title('near IR2: 860-1040 nm'); fig.colorbar(img, ax=ax[2][1], fraction=0.05)\n",
    "    img = ax[2][2].imshow(rawDataTrain['AGL'][imgIdx].astype(np.uint8), cmap='gray'); ax[2][2].set_title('AGL'); fig.colorbar(img, ax=ax[2][2], fraction=0.05)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.savefig('./plots/rawData.svg')\n",
    "\n",
    "    '''\n",
    "    Compute Features\n",
    "    '''\n",
    "    dataTrain = dataStack(rawDataTrain)\n",
    "    ## Compute features\n",
    "    dataTrain = pd.DataFrame( np.array(dataTrain) , columns=colNames )\n",
    "    # dataTrain = featuresCompute(dataTrain, numPCA=3, numICA=3 )\n",
    "    print(f'Feature Names:\\n{dataTrain.columns}')\n",
    "\n",
    "    '''\n",
    "    Remove Irrelevant Classes\n",
    "    '''\n",
    "    groundTruthCLS = np.array(dataTrain['CLS'])\n",
    "    groundTruthCLS[np.where(groundTruthCLS==9)[0]] = 2\n",
    "    groundTruthCLS[np.where(groundTruthCLS==17)[0]] = 2\n",
    "    groundTruthCLS[np.where(groundTruthCLS==65)[0]] = 2\n",
    "    groundTruthCLS[np.where(groundTruthCLS==2)[0]] = 0\n",
    "\n",
    "    trainGroundTruth = vectorStackToImage(pd.DataFrame(groundTruthCLS,columns=['CLS']),colNames=['CLS'])\n",
    "    del groundTruthCLS\n",
    "\n",
    "    fig,ax = plt.subplots(nrows=1,ncols=3,figsize=(12,4))\n",
    "    img = ax[0].imshow((trainGroundTruth['CLS'][imgIdx]==6).astype(np.uint8), cmap='gray'); ax[0].set_title('Class Labels: \\nBuildings (6)'); fig.colorbar(img, ax=ax[0], fraction=0.05)\n",
    "    img = ax[1].imshow((trainGroundTruth['CLS'][imgIdx]==5).astype(np.uint8), cmap='Greens'); ax[1].set_title('Class Labels: \\nTrees (5)'); fig.colorbar(img, ax=ax[1], fraction=0.05)\n",
    "    img = ax[2].imshow((trainGroundTruth['CLS'][imgIdx]==0).astype(np.uint8), cmap='YlOrRd_r'); ax[2].set_title('Class Labels: \\nOther (0)'); fig.colorbar(img, ax=ax[2], fraction=0.05)\n",
    "    fig.tight_layout()\n",
    "    plt.savefig('./plots/rawDataCLSReduced.svg')\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59af466a-5d96-423a-af2d-877019bbd5ba",
   "metadata": {},
   "source": [
    "## Pre-Process Data\n",
    "Labels: 6: Building, 3: Tree, 0: Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5e7ecf5-f4d0-4ae3-9940-ab02e93bcbc3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preProcessImgs2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_38020/4103425792.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mXTrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mYTrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreProcessImgs2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgFolder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mannotationFolder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'trainImgCLS'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'preProcessImgs2' is not defined"
     ]
    }
   ],
   "source": [
    "XTrain,YTrain,cols = preProcessImgs2(imgFolder='train',annotationFolder='trainImgCLS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f391732f-0f48-4a2b-a3fd-24ba4cbd0544",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "XValid,YValid,cols = preProcessImgs2(imgFolder='test2_assignment_2_sim',annotationFolder='validImgCLS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d6d9c9-0275-45c9-93f4-ab1694933169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XTest,YTest,cols = preProcessImgs2(imgFolder='test1',annotationFolder='testImgCLS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc8d64a-0fef-481f-afd1-18b277f118bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subimagesDataset(dataset,subimgSize=(256,256)):\n",
    "    def subimages(img,subimgSize):\n",
    "        imgList = []\n",
    "        for i in range(0,img.shape[0],subimgSize[0]):\n",
    "            for j in range(0,img.shape[1],subimgSize[1]):\n",
    "                imgList.append(img[0+i:i+subimgSize[0],0+j:j+subimgSize[1]])\n",
    "        return np.array(imgList).astype(np.float32)\n",
    "    \n",
    "    subimagesAll = subimages(dataset[0],subimgSize)   \n",
    "    for img in dataset[1:]:\n",
    "        subimagesAll = np.concatenate((subimagesAll,subimages(img,subimgSize)) , axis=0)\n",
    "    return subimagesAll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03b0d8b-e0c1-49e8-b9b2-cd42210eac8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrain = subimagesDataset(XTrain,subimgSize=(256,256))\n",
    "YTrain = subimagesDataset(YTrain,subimgSize=(256,256))\n",
    "\n",
    "print(XTrain.shape)\n",
    "print(YTrain.shape)\n",
    "\n",
    "XValid = subimagesDataset(XValid,subimgSize=(256,256))\n",
    "YValid = subimagesDataset(YValid,subimgSize=(256,256))\n",
    "\n",
    "print(XValid.shape)\n",
    "print(YValid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7df367-0107-4f03-943e-696dc7934ff3",
   "metadata": {},
   "source": [
    "# U-NET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f710e179-8d4c-4aa4-91ed-0c7526cf8eb7",
   "metadata": {},
   "source": [
    "### Model: Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352c7bfc-c807-4572-b1b6-fb1b1e790c31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input,Conv2D,BatchNormalization,Activation,MaxPool2D,UpSampling2D,Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "def conv_block(inputs,filters,pool=True):\n",
    "    x = Conv2D(filters,3,padding='same')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    x = Conv2D(filters,3,padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    if pool == True:\n",
    "        p = MaxPool2D((2,2))(x)\n",
    "        return x,p\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "def build_unet(shape,num_classes):\n",
    "    inputs = Input(shape)\n",
    "\n",
    "    \"\"\"Encoder\"\"\"\n",
    "    x1,p1 = conv_block(inputs,64,pool=True)\n",
    "    x2,p2 = conv_block(p1,128,pool=True)\n",
    "    x3,p3 = conv_block(p2,256,pool=True)\n",
    "    x4,p4 = conv_block(p3,512,pool=True)\n",
    "    \n",
    "    \"\"\"Bridge\"\"\"\n",
    "    b1 = conv_block(p4,1024,pool=False)\n",
    "\n",
    "    \"\"\"Decoder\"\"\"    \n",
    "    u1 = UpSampling2D((2,2),interpolation=\"bilinear\")(b1)\n",
    "    c1 = Concatenate()([u1,x4])\n",
    "    x5 = conv_block(c1,512,pool=False)\n",
    "\n",
    "    u2 = UpSampling2D((2,2),interpolation=\"bilinear\")(x5)\n",
    "    c2 = Concatenate()([u2,x3])\n",
    "    x6 = conv_block(c2,256,pool=False)\n",
    "    \n",
    "    u3 = UpSampling2D((2,2),interpolation=\"bilinear\")(x6)\n",
    "    c3 = Concatenate()([u3,x2])\n",
    "    x7 = conv_block(c3,128,pool=False)\n",
    "\n",
    "    u4 = UpSampling2D((2,2),interpolation=\"bilinear\")(x7)\n",
    "    c4 = Concatenate()([u4,x1])\n",
    "    x8 = conv_block(c4,64,pool=False)\n",
    "    \n",
    "    \n",
    "    \"\"\"Output\"\"\"\n",
    "    output = Conv2D(num_classes, 1,padding='same',activation=\"softmax\")(x8)\n",
    "\n",
    "    return Model(inputs,output)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model = build_unet((256,256,9),3)\n",
    "    print(model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282bca95-088e-449b-8cbd-44d152b8fe5f",
   "metadata": {},
   "source": [
    "### Model: Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faae7dd5-874c-47e2-9cab-1c9561357752",
   "metadata": {},
   "outputs": [],
   "source": [
    "H = 256\n",
    "W = 256\n",
    "numClasses = 3\n",
    "numFeatures = len(cols)\n",
    "batchsize=8\n",
    "lr = 1e-3\n",
    "epochs=15\n",
    "shape = (H,W,numFeatures)\n",
    "\n",
    "def preprocess(x,y):\n",
    "    image = tf.convert_to_tensor(x.astype(np.float32), dtype=tf.float32)\n",
    "    mask = tf.convert_to_tensor(y.astype(np.int32), dtype=tf.int32)\n",
    "    mask = tf.one_hot(mask,numClasses,dtype=tf.int32)\n",
    "    image.set_shape([len(x),H,W,numFeatures])\n",
    "    mask.set_shape([len(x),H,W,numClasses])\n",
    "    return image,mask\n",
    "\n",
    "def tf_dataset(x,y,batch=8):\n",
    "    X0,Y0 = preprocess(x,y)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((X0,Y0))\n",
    "    dataset = dataset.shuffle(buffer_size=5000)\n",
    "    dataset = dataset.batch(batch)\n",
    "    dataset = dataset.prefetch(2)\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163af452-3f83-4af8-b2d8-b98010e0758d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf_dataset(np.nan_to_num(XTrain,nan=0),YTrain,batch=batchsize)\n",
    "valid_dataset = tf_dataset(np.nan_to_num(XValid,nan=0),YValid,batch=batchsize)\n",
    "\n",
    "print('Training Batches')\n",
    "for x,y in train_dataset:\n",
    "    print(x.shape,y.shape)\n",
    "print('\\nValidation Batches')\n",
    "for x,y in valid_dataset:\n",
    "    print(x.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3062c39-c4a7-450c-8627-ff326c074468",
   "metadata": {},
   "outputs": [],
   "source": [
    "YTrain.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32ed002-c22d-4677-89b6-73eba2405329",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c630b83-b95c-4c7e-8a5d-51f2dbf8d998",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint,ReduceLROnPlateau,EarlyStopping\n",
    "\n",
    "\"\"\" U-Net Model \"\"\"\n",
    "model = build_unet(shape,numClasses)\n",
    "model.compile(loss='categorical_crossentropy',optimizer=tf.keras.optimizers.Adam(lr))\n",
    "\n",
    "train_steps = len(XTrain)//batchsize\n",
    "valid_steps = len(XValid)//batchsize\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\"modelUnet.h5\",verbose=1,save_best_model=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss',patience=3,factor=0.1,verbose=1,min_lr=1e-6),\n",
    "    EarlyStopping(monitor='val_loss',patience=5,verbose=1)\n",
    "]\n",
    "\n",
    "model.fit(train_dataset,\n",
    "    steps_per_epoch=train_steps,\n",
    "    validation_data=valid_dataset,\n",
    "    validation_steps=valid_steps,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c6feb5-4042-412b-b7f7-aa2a358d96cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('modelUnet.h5')\n",
    "predictionsSoftmax = model.predict(XValid)\n",
    "predictions = np.argmax(predictionsSoftmax, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118f9ba6-05d7-4b0e-8e90-d6ecd7360165",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(nrows=2,ncols=np.ceil(len(YValid)/32).astype(int),figsize=(15,7),dpi=150)\n",
    "ax = ax.reshape(-1)\n",
    "i=0\n",
    "for imgIdx in range(3,len(YValid),16):\n",
    "    ax[i].imshow(YValid[imgIdx],cmap='gray')\n",
    "    # plt.colorbar()\n",
    "    i=i+1\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig,ax = plt.subplots(nrows=2,ncols=np.ceil(len(YValid)/32).astype(int),figsize=(15,7),dpi=150)\n",
    "ax = ax.reshape(-1)\n",
    "i=0\n",
    "for imgIdx in range(3,len(YValid),16):\n",
    "    ax[i].imshow(predictions[imgIdx],cmap='Reds')\n",
    "    # plt.colorbar()\n",
    "    i=i+1\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7624f5-9b9b-48eb-834b-f42e72128f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf6c7ff-9cad-4d96-b88f-970b4767e069",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsSoftmax[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262ff15c-c7df-4df5-9c75-88626db24157",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(YValid[19])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0a3946-153a-4bf4-aa58-efdc20e07743",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
